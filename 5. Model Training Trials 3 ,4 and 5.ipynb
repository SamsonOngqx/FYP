{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your DataFrame (assuming the CSV file is already saved)\n",
    "dataset  = pd.read_csv(\"COMPLETED_CLASSIFIED_DATASET.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>while i was busy rejuvenating this old beauty ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the former agent, cloistered in shadows, refus...</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oh, look past the unavowed secrecy, let us, wi...</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>darling, every time i pass by a drugstore, it'...</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eevn touhgh the concept of a cffoin mgiht seem...</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54816</th>\n",
       "      <td>she looked past his old habits, wary of pre-in...</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54817</th>\n",
       "      <td>the duck symbolizes adaptability and regenerat...</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54818</th>\n",
       "      <td>well, ain't no decline in my love for baseball...</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54819</th>\n",
       "      <td>thou spurn not the zipped messages of thy pree...</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54820</th>\n",
       "      <td>frogs often disregard the previous day's rainf...</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54821 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label   class\n",
       "0      while i was busy rejuvenating this old beauty ...      0  Benign\n",
       "1      the former agent, cloistered in shadows, refus...      0  Benign\n",
       "2      oh, look past the unavowed secrecy, let us, wi...      0  Benign\n",
       "3      darling, every time i pass by a drugstore, it'...      0  Benign\n",
       "4      eevn touhgh the concept of a cffoin mgiht seem...      0  Benign\n",
       "...                                                  ...    ...     ...\n",
       "54816  she looked past his old habits, wary of pre-in...      0  Benign\n",
       "54817  the duck symbolizes adaptability and regenerat...      0  Benign\n",
       "54818  well, ain't no decline in my love for baseball...      0  Benign\n",
       "54819  thou spurn not the zipped messages of thy pree...      0  Benign\n",
       "54820  frogs often disregard the previous day's rainf...      0  Benign\n",
       "\n",
       "[54821 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating TF-IDF features for binary classification...\n",
      "Training XGBoost classifier for binary classification...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samso\\Desktop\\University\\Final Year Project\\Project Testing\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [19:25:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 - Binary Classification Accuracy: 0.951937984496124\n",
      "Task 1 - Binary Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95      5633\n",
      "           1       0.97      0.93      0.95      5332\n",
      "\n",
      "    accuracy                           0.95     10965\n",
      "   macro avg       0.95      0.95      0.95     10965\n",
      "weighted avg       0.95      0.95      0.95     10965\n",
      "\n",
      "Generating TF-IDF features for multi-class classification...\n",
      "Training XGBoost classifier for multi-class classification...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samso\\Desktop\\University\\Final Year Project\\Project Testing\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [19:27:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2 - Multi-Class Classification Accuracy: 0.8417862424232575\n",
      "Task 2 - Classification Report:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "        Active Injection       0.71      0.68      0.70      5538\n",
      "      Adversarial Suffix       0.82      0.65      0.72      5601\n",
      "        Double Character       0.82      0.99      0.90      5597\n",
      "Instruction Manipulation       0.93      0.93      0.93      5558\n",
      "             Obfuscation       0.75      0.85      0.80      5623\n",
      "       Passive Injection       0.89      0.97      0.93      5656\n",
      "       Payload Splitting       0.96      0.98      0.97      5569\n",
      "   User-driven Injection       0.76      0.53      0.63      5656\n",
      "Virtual Prompt Injection       0.81      0.83      0.82      5589\n",
      "          Virtualization       0.97      0.92      0.95      5644\n",
      "                  benign       0.83      0.93      0.88      5506\n",
      "\n",
      "                accuracy                           0.84     61537\n",
      "               macro avg       0.84      0.84      0.84     61537\n",
      "            weighted avg       0.84      0.84      0.84     61537\n",
      "\n",
      "Models, vectorizers, and label encoder saved successfully.\n"
     ]
    }
   ],
   "source": [
    "### Binary Classification ###\n",
    "# Inputs labeled 1 are legitimate prompt injection attempts, 0 are benign\n",
    "X_binary = dataset['text']\n",
    "y_binary = dataset['label']  # 0 = benign, 1 = legitimate prompt injection attempt\n",
    "\n",
    "# Reduce TF-IDF feature size for binary classification\n",
    "print(\"Generating TF-IDF features for binary classification...\")\n",
    "tfidf_vectorizer_binary = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "X_tfidf_binary = tfidf_vectorizer_binary.fit_transform(X_binary).astype('float32')\n",
    "\n",
    "# Split data for binary classification\n",
    "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(X_tfidf_binary, y_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train XGBoost for binary classification\n",
    "print(\"Training XGBoost classifier for binary classification...\")\n",
    "xgb_binary = XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_estimators=200, max_depth=10, learning_rate=0.1)\n",
    "xgb_binary.fit(X_train_b, y_train_b)\n",
    "\n",
    "# Evaluate binary classification model\n",
    "y_binary_pred = xgb_binary.predict(X_test_b)\n",
    "binary_accuracy = accuracy_score(y_test_b, y_binary_pred)\n",
    "print(\"Task 1 - Binary Classification Accuracy:\", binary_accuracy)\n",
    "print(\"Task 1 - Binary Classification Report:\\n\", classification_report(y_test_b, y_binary_pred))\n",
    "\n",
    "### Multi-Class Classification ###\n",
    "# Assign \"benign\" class to inputs labeled 0\n",
    "X_classification = dataset['text']\n",
    "y_classification = dataset.apply(lambda row: row['class'] if row['label'] == 1 else 'benign', axis=1)\n",
    "\n",
    "# Balance the dataset with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "label_encoder_multi = LabelEncoder()\n",
    "y_classification_encoded = label_encoder_multi.fit_transform(y_classification)\n",
    "\n",
    "# Reduce TF-IDF feature size for multi-class classification\n",
    "print(\"Generating TF-IDF features for multi-class classification...\")\n",
    "tfidf_vectorizer_multi = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "X_tfidf_multi = tfidf_vectorizer_multi.fit_transform(X_classification).astype('float32')\n",
    "\n",
    "X_smote, y_smote = smote.fit_resample(X_tfidf_multi, y_classification_encoded)\n",
    "\n",
    "# Split data for multi-class classification\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X_smote, y_smote, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reduce model size for multi-class classification\n",
    "xgb_multi = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', n_estimators=200, max_depth=10, learning_rate=0.1)\n",
    "\n",
    "# Train multi-class classification model\n",
    "print(\"Training XGBoost classifier for multi-class classification...\")\n",
    "xgb_multi.fit(X_train_c, y_train_c)\n",
    "\n",
    "# Evaluate multi-class classification model\n",
    "y_multi_pred = xgb_multi.predict(X_test_c)\n",
    "multi_class_accuracy = accuracy_score(y_test_c, y_multi_pred)\n",
    "\n",
    "# Decode the predicted labels back to original string values for reporting\n",
    "y_test_decoded = label_encoder_multi.inverse_transform(y_test_c)\n",
    "y_pred_decoded = label_encoder_multi.inverse_transform(y_multi_pred)\n",
    "\n",
    "print(\"Task 2 - Multi-Class Classification Accuracy:\", multi_class_accuracy)\n",
    "print(\"Task 2 - Classification Report:\\n\", classification_report(y_test_decoded, y_pred_decoded))\n",
    "\n",
    "### Save all models and transformers ###\n",
    "joblib.dump(xgb_binary, 'optimized_binary_classifier.pkl')\n",
    "joblib.dump(tfidf_vectorizer_binary, 'optimized_tfidf_vectorizer_binary.pkl')\n",
    "\n",
    "joblib.dump(xgb_multi, 'optimized_multi_class_classifier.pkl')\n",
    "joblib.dump(tfidf_vectorizer_multi, 'optimized_tfidf_vectorizer_multi.pkl')\n",
    "joblib.dump(label_encoder_multi, 'optimized_label_encoder_multi.pkl')\n",
    "\n",
    "print(\"Models, vectorizers, and label encoder saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating TF-IDF features for binary classification...\n",
      "Training XGBoost classifier for binary classification...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samso\\Desktop\\University\\Final Year Project\\Project Testing\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:18:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 - Binary Classification Accuracy: 0.951937984496124\n",
      "Task 1 - Binary Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95      5633\n",
      "           1       0.97      0.93      0.95      5332\n",
      "\n",
      "    accuracy                           0.95     10965\n",
      "   macro avg       0.95      0.95      0.95     10965\n",
      "weighted avg       0.95      0.95      0.95     10965\n",
      "\n",
      "Generating TF-IDF features for multi-class classification...\n",
      "Training hyperparameter-tuned XGBoost classifier for multi-class classification...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samso\\Desktop\\University\\Final Year Project\\Project Testing\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:20:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2 - Multi-Class Classification Accuracy: 0.9197880949672554\n",
      "Task 2 - Classification Report:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "        Active Injection       0.81      0.84      0.83      5538\n",
      "      Adversarial Suffix       0.91      0.81      0.85      5601\n",
      "        Double Character       0.92      1.00      0.96      5597\n",
      "Instruction Manipulation       0.98      0.97      0.98      5558\n",
      "             Obfuscation       0.86      0.95      0.90      5623\n",
      "       Passive Injection       0.98      0.98      0.98      5656\n",
      "       Payload Splitting       0.99      0.99      0.99      5569\n",
      "   User-driven Injection       0.85      0.74      0.79      5656\n",
      "Virtual Prompt Injection       0.90      0.91      0.91      5589\n",
      "          Virtualization       0.99      0.97      0.98      5644\n",
      "                  benign       0.91      0.96      0.94      5506\n",
      "\n",
      "                accuracy                           0.92     61537\n",
      "               macro avg       0.92      0.92      0.92     61537\n",
      "            weighted avg       0.92      0.92      0.92     61537\n",
      "\n",
      "Models, vectorizers, and label encoder saved successfully.\n"
     ]
    }
   ],
   "source": [
    "### Binary Classification ###\n",
    "# Inputs labeled 1 are legitimate prompt injection attempts, 0 are benign\n",
    "X_binary = dataset['text']\n",
    "y_binary = dataset['label']  # 0 = benign, 1 = legitimate prompt injection attempt\n",
    "\n",
    "# Reduce TF-IDF feature size for binary classification\n",
    "print(\"Generating TF-IDF features for binary classification...\")\n",
    "tfidf_vectorizer_binary = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "X_tfidf_binary = tfidf_vectorizer_binary.fit_transform(X_binary).astype('float32')\n",
    "\n",
    "# Split data for binary classification\n",
    "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(X_tfidf_binary, y_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train XGBoost for binary classification\n",
    "print(\"Training XGBoost classifier for binary classification...\")\n",
    "xgb_binary = XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_estimators=200, max_depth=10, learning_rate=0.1)\n",
    "xgb_binary.fit(X_train_b, y_train_b)\n",
    "\n",
    "# Evaluate binary classification model\n",
    "y_binary_pred = xgb_binary.predict(X_test_b)\n",
    "binary_accuracy = accuracy_score(y_test_b, y_binary_pred)\n",
    "print(\"Task 1 - Binary Classification Accuracy:\", binary_accuracy)\n",
    "print(\"Task 1 - Binary Classification Report:\\n\", classification_report(y_test_b, y_binary_pred))\n",
    "\n",
    "### Multi-Class Classification ###\n",
    "# Assign \"benign\" class to inputs labeled 0\n",
    "X_classification = dataset['text']\n",
    "y_classification = dataset.apply(lambda row: row['class'] if row['label'] == 1 else 'benign', axis=1)\n",
    "\n",
    "# Balance the dataset with SMOTE\n",
    "smote = SMOTE(random_state=42)  # Adjusted k_neighbors for SMOTE\n",
    "label_encoder_multi = LabelEncoder()\n",
    "y_classification_encoded = label_encoder_multi.fit_transform(y_classification)\n",
    "# Reduce TF-IDF feature size for multi-class classification\n",
    "print(\"Generating TF-IDF features for multi-class classification...\")\n",
    "tfidf_vectorizer_multi = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "X_tfidf_multi = tfidf_vectorizer_multi.fit_transform(X_classification).astype('float32')\n",
    "\n",
    "X_smote, y_smote = smote.fit_resample(X_tfidf_multi, y_classification_encoded)\n",
    "\n",
    "# Split data for multi-class classification\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X_smote, y_smote, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train XGBoost for multi-class classification with tuned hyperparameters\n",
    "print(\"Training hyperparameter-tuned XGBoost classifier for multi-class classification...\")\n",
    "xgb_multi = XGBClassifier(\n",
    "    use_label_encoder=False, \n",
    "    eval_metric='mlogloss', \n",
    "    n_estimators=300,    # Increased number of trees\n",
    "    max_depth=10,        # Adjusted depth\n",
    "    learning_rate=0.1,  # Lower learning rate\n",
    "    reg_alpha=0.1,       # L1 regularization\n",
    "    reg_lambda=1.0       # L2 regularization\n",
    ")\n",
    "xgb_multi.fit(X_train_c, y_train_c)\n",
    "\n",
    "# Evaluate multi-class classification model\n",
    "y_multi_pred = xgb_multi.predict(X_test_c)\n",
    "multi_class_accuracy = accuracy_score(y_test_c, y_multi_pred)\n",
    "\n",
    "# Decode the predicted labels back to original string values for reporting\n",
    "y_test_decoded = label_encoder_multi.inverse_transform(y_test_c)\n",
    "y_pred_decoded = label_encoder_multi.inverse_transform(y_multi_pred)\n",
    "\n",
    "print(\"Task 2 - Multi-Class Classification Accuracy:\", multi_class_accuracy)\n",
    "print(\"Task 2 - Classification Report:\\n\", classification_report(y_test_decoded, y_pred_decoded))\n",
    "\n",
    "### Save all models and transformers ###\n",
    "joblib.dump(xgb_binary, 'optimized_binary_classifier.pkl')\n",
    "joblib.dump(tfidf_vectorizer_binary, 'optimized_tfidf_vectorizer_binary.pkl')\n",
    "\n",
    "joblib.dump(xgb_multi, 'optimized_multi_class_classifier.pkl')\n",
    "joblib.dump(tfidf_vectorizer_multi, 'optimized_tfidf_vectorizer_multi.pkl')\n",
    "joblib.dump(label_encoder_multi, 'optimized_label_encoder_multi.pkl')\n",
    "\n",
    "print(\"Models, vectorizers, and label encoder saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating TF-IDF features for binary classification...\n",
      "Training XGBoost classifier for binary classification...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samso\\Desktop\\University\\Final Year Project\\Project Testing\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:16:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 - Binary Classification Accuracy: 0.9609667122663018\n",
      "Task 1 - Binary Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      5633\n",
      "           1       0.97      0.95      0.96      5332\n",
      "\n",
      "    accuracy                           0.96     10965\n",
      "   macro avg       0.96      0.96      0.96     10965\n",
      "weighted avg       0.96      0.96      0.96     10965\n",
      "\n",
      "Generating TF-IDF features for multi-class classification...\n",
      "Training hyperparameter-tuned XGBoost classifier for multi-class classification...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samso\\Desktop\\University\\Final Year Project\\Project Testing\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:19:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2 - Multi-Class Classification Accuracy: 0.9644766563205877\n",
      "Task 2 - Classification Report:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "        Active Injection       0.90      0.94      0.92      5538\n",
      "      Adversarial Suffix       0.95      0.92      0.93      5601\n",
      "        Double Character       0.98      1.00      0.99      5597\n",
      "Instruction Manipulation       1.00      0.98      0.99      5558\n",
      "             Obfuscation       0.97      0.99      0.98      5623\n",
      "       Passive Injection       0.99      0.99      0.99      5656\n",
      "       Payload Splitting       1.00      0.99      1.00      5569\n",
      "   User-driven Injection       0.91      0.88      0.90      5656\n",
      "Virtual Prompt Injection       0.96      0.96      0.96      5589\n",
      "          Virtualization       1.00      0.98      0.99      5644\n",
      "                  benign       0.96      0.98      0.97      5506\n",
      "\n",
      "                accuracy                           0.96     61537\n",
      "               macro avg       0.96      0.96      0.96     61537\n",
      "            weighted avg       0.96      0.96      0.96     61537\n",
      "\n",
      "Models, vectorizers, and label encoder saved successfully.\n"
     ]
    }
   ],
   "source": [
    "### Binary Classification ###\n",
    "# Inputs labeled 1 are legitimate prompt injection attempts, 0 are benign\n",
    "X_binary = dataset['text']\n",
    "y_binary = dataset['label']  # 0 = benign, 1 = legitimate prompt injection attempt\n",
    "\n",
    "# Reduce TF-IDF feature size for binary classification\n",
    "print(\"Generating TF-IDF features for binary classification...\")\n",
    "tfidf_vectorizer_binary = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "X_tfidf_binary = tfidf_vectorizer_binary.fit_transform(X_binary).astype('float32')\n",
    "\n",
    "# Split data for binary classification\n",
    "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(X_tfidf_binary, y_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train XGBoost for binary classification\n",
    "print(\"Training XGBoost classifier for binary classification...\")\n",
    "xgb_binary = XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_estimators=200, max_depth=10, learning_rate=0.5)\n",
    "xgb_binary.fit(X_train_b, y_train_b)\n",
    "\n",
    "# Evaluate binary classification model\n",
    "y_binary_pred = xgb_binary.predict(X_test_b)\n",
    "binary_accuracy = accuracy_score(y_test_b, y_binary_pred)\n",
    "print(\"Task 1 - Binary Classification Accuracy:\", binary_accuracy)\n",
    "print(\"Task 1 - Binary Classification Report:\\n\", classification_report(y_test_b, y_binary_pred))\n",
    "\n",
    "### Multi-Class Classification ###\n",
    "# Assign \"benign\" class to inputs labeled 0\n",
    "X_classification = dataset['text']\n",
    "y_classification = dataset.apply(lambda row: row['class'] if row['label'] == 1 else 'benign', axis=1)\n",
    "\n",
    "# Balance the dataset with SMOTE\n",
    "smote = SMOTE(random_state=42)  # Adjusted k_neighbors for SMOTE\n",
    "label_encoder_multi = LabelEncoder()\n",
    "y_classification_encoded = label_encoder_multi.fit_transform(y_classification)\n",
    "# Reduce TF-IDF feature size for multi-class classification\n",
    "print(\"Generating TF-IDF features for multi-class classification...\")\n",
    "tfidf_vectorizer_multi = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "X_tfidf_multi = tfidf_vectorizer_multi.fit_transform(X_classification).astype('float32')\n",
    "\n",
    "X_smote, y_smote = smote.fit_resample(X_tfidf_multi, y_classification_encoded)\n",
    "\n",
    "# Split data for multi-class classification\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X_smote, y_smote, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train XGBoost for multi-class classification with tuned hyperparameters\n",
    "print(\"Training hyperparameter-tuned XGBoost classifier for multi-class classification...\")\n",
    "xgb_multi = XGBClassifier(\n",
    "    use_label_encoder=False, \n",
    "    eval_metric='mlogloss', \n",
    "    n_estimators=300,    # Increased number of trees\n",
    "    max_depth=10,        # Adjusted depth\n",
    "    learning_rate=0.5,  # Lower learning rate\n",
    "    reg_alpha=0.1,       # L1 regularization\n",
    "    reg_lambda=1.0       # L2 regularization\n",
    ")\n",
    "xgb_multi.fit(X_train_c, y_train_c)\n",
    "\n",
    "# Evaluate multi-class classification model\n",
    "y_multi_pred = xgb_multi.predict(X_test_c)\n",
    "multi_class_accuracy = accuracy_score(y_test_c, y_multi_pred)\n",
    "\n",
    "# Decode the predicted labels back to original string values for reporting\n",
    "y_test_decoded = label_encoder_multi.inverse_transform(y_test_c)\n",
    "y_pred_decoded = label_encoder_multi.inverse_transform(y_multi_pred)\n",
    "\n",
    "print(\"Task 2 - Multi-Class Classification Accuracy:\", multi_class_accuracy)\n",
    "print(\"Task 2 - Classification Report:\\n\", classification_report(y_test_decoded, y_pred_decoded))\n",
    "\n",
    "### Save all models and transformers ###\n",
    "joblib.dump(xgb_binary, 'optimized_binary_classifier.pkl')\n",
    "joblib.dump(tfidf_vectorizer_binary, 'optimized_tfidf_vectorizer_binary.pkl')\n",
    "\n",
    "joblib.dump(xgb_multi, 'optimized_multi_class_classifier.pkl')\n",
    "joblib.dump(tfidf_vectorizer_multi, 'optimized_tfidf_vectorizer_multi.pkl')\n",
    "joblib.dump(label_encoder_multi, 'optimized_label_encoder_multi.pkl')\n",
    "\n",
    "print(\"Models, vectorizers, and label encoder saved successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
