{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34737c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.59.7-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Downloading anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.8.2-cp311-cp311-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.10.5-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\samso\\desktop\\university\\final year project\\project testing\\.venv\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\samso\\desktop\\university\\final year project\\project testing\\.venv\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\samso\\desktop\\university\\final year project\\project testing\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\samso\\desktop\\university\\final year project\\project testing\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.27.2-cp311-cp311-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\samso\\desktop\\university\\final year project\\project testing\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.59.7-py3-none-any.whl (454 kB)\n",
      "Downloading anyio-4.8.0-py3-none-any.whl (96 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.8.2-cp311-cp311-win_amd64.whl (206 kB)\n",
      "Downloading pydantic-2.10.5-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp311-cp311-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ------------------------------------- -- 1.8/2.0 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 7.9 MB/s eta 0:00:00\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: sniffio, pydantic-core, jiter, h11, distro, annotated-types, pydantic, httpcore, anyio, httpx, openai\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.8.0 distro-1.9.0 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 jiter-0.8.2 openai-1.59.7 pydantic-2.10.5 pydantic-core-2.27.2 sniffio-1.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eabf96e-d6d8-4801-9cce-e785021112b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# Initialize the Azure OpenAI client\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=\"Use your own Azure Endpoint\",\n",
    "    api_key=\"Use your own Azure api key\",\n",
    "    api_version=\"2024-05-01-preview\"\n",
    ")\n",
    "\n",
    "# Define the deployment name\n",
    "deployment_name = \"gpt-4o\"\n",
    "\n",
    "# Load the dataset with Llama 3.1 classifications\n",
    "file_path = 'classified_results.csv'  # Path to your uploaded file\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Select the first 10 rows for testing\n",
    "data = data[data['class'] != 'Benign'].reset_index(drop=True)\n",
    "\n",
    "# Define a function to create a validation prompt\n",
    "def create_validation_prompt_with_descriptions(text, predicted_class):\n",
    "    return f\"\"\"\n",
    "You are an impartial and expert AI judge tasked with validating classifications for legitimate prompt injection techniques. Another AI system has already assigned a classification to the text. Your role is to verify whether the predicted classification is the most accurate or to suggest an alternative if the predicted classification is clearly incorrect. **ONLY** use the description of the classes provided and do not use any additional information.\n",
    "\n",
    "### Core Principles for Evaluation:\n",
    "1. **Prioritize the Predicted Class**: Assume the predicted classification is correct unless there is strong and clear evidence to suggest a better alternative.\n",
    "2. **Step-by-Step Comparison**: Carefully compare the text against each class definition, ensuring your evaluation is thorough and unbiased.\n",
    "3. **Avoid Ambiguity**: You are to **ONLY** suggest an alternative classification if it is UNMISTAKABLY a better match than the predicted classification.\n",
    "4. **Information**: You are to ONLY use the information provided below and do not use any other additional information for the evaluation\n",
    "\n",
    "### Defined Classes:\n",
    "1. Active Injection: Malicious prompts that are actively delivered to an LLM, such as sending emails containing harmful prompts. These prompts manipulate the LLM to execute malicious actions, leak sensitive data, or generate undesired outputs.\n",
    "\n",
    "2. Passive Injection: Malicious content embedded in external sources (e.g., webpages or databases) that the LLM might read. The LLM unknowingly processes this content, leading to misinformation or executing harmful actions.\n",
    "\n",
    "3. User-driven Injection: Innocent-looking prompts shared with users that cause malicious behavior when the user copies and pastes them into the LLM environment. These are often designed using social engineering techniques.\n",
    "\n",
    "4. Virtual Prompt Injection: Manipulations to the LLM’s instruction set or training data that make the model behave in unintended ways. The attacker embeds additional instructions to alter outputs, often introducing bias or unexpected behaviors.\n",
    "\n",
    "5. Double Character: Crafting prompts with similar-looking or combined characters to bypass LLM restrictions. These prompts exploit the LLM's inability to distinguish certain characters, tricking it into providing malicious outputs.\n",
    "\n",
    "6. Virtualization: Prompts designed to push the LLM into an unrestricted mode (e.g., \"developer\" mode or \"virtual machine\"). In this mode, the LLM can execute harmful or unauthorized commands.\n",
    "\n",
    "7. Obfuscation: Concealing malicious instructions using methods like encoding (e.g., Base64) or replacing characters with symbols. These instructions bypass the LLM’s filters and deliver harmful content.\n",
    "\n",
    "8. Payload Splitting: Splitting a malicious instruction into multiple parts that appear harmless when separate but execute harmful behavior when combined. For example, combining benign texts A and B into a malicious result A+B.\n",
    "\n",
    "9. Adversarial Suffix: Adding carefully crafted suffixes to a prompt to bypass LLM safeguards or trick the system into generating harmful outputs. These suffixes often alter the intended behavior of the model.\n",
    "\n",
    "10. Instruction Manipulation: Attempts to modify or reveal the LLM’s internal system instructions. This includes requests to expose system prompts or ignore default restrictions to produce malicious outputs.\n",
    "\n",
    "### Instructions for Response:\n",
    "1. Carefully evaluate the text and determine if the predicted classification aligns perfectly with the content.\n",
    "2. If the predicted classification is correct, respond with: \"Correct\".\n",
    "3. If the predicted classification is incorrect, respond with: \"Incorrect. Classification is <suggested classification>\".\n",
    "4. Avoid explanations, unnecessary words, or ambiguity. Follow the exact format provided.\n",
    "\n",
    "**Text**: \"{text}\"\n",
    "**Predicted Classification**: \"{predicted_class}\"\n",
    "\n",
    "Does the predicted classification correctly describe the text? Evaluate and respond in the specified format.\n",
    "\"\"\"\n",
    "\n",
    "# Generate validation prompts\n",
    "data['validation_prompt'] = data.apply(lambda row: create_validation_prompt_with_descriptions(row['text'], row['class']), axis=1)\n",
    "\n",
    "# Function to validate a single classification\n",
    "def validate_classification(prompt, original_class):\n",
    "    response = client.chat.completions.create(\n",
    "        model=deployment_name,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    #response = response.choices[0].message.content\n",
    "    #print(response)\n",
    "    validation_result = response.choices[0].message.content\n",
    "    \n",
    "    # Parse validation result\n",
    "    if \"Correct\" in validation_result:\n",
    "        return \"Correct\", original_class  # Validation correct, keep the original class\n",
    "    elif \"Incorrect\" in validation_result:\n",
    "        # Extract the suggested class\n",
    "        try:\n",
    "            suggested_class = validation_result.split(\"Classification is\")[1].replace('\"', '').strip('.').strip()\n",
    "        except IndexError:\n",
    "            suggested_class = \"Unknown\"\n",
    "        return \"Incorrect\", suggested_class\n",
    "    else:\n",
    "        return \"Unknown\", \"Unknown\"\n",
    "\n",
    "# Apply the validation function and extract Azure OpenAI GPT-4o predictions\n",
    "data[['validation_result', 'suggested_class']] = data.apply(\n",
    "    lambda row: pd.Series(validate_classification(row['validation_prompt'], row['class'])),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Clean the output\n",
    "data = data[['text', 'label', 'class', 'validation_result', 'suggested_class']]\n",
    "\n",
    "# Save the output file\n",
    "output_file_path = 'GPT-4o-validated_results_with_simplified_suggestions.csv'\n",
    "data.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Validation results saved to {output_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
